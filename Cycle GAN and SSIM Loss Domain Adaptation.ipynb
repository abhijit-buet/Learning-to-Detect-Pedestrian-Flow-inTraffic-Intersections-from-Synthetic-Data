{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/home/abhijit/Downloads/video frames/crowd/'\n",
    "csv = '/home/abhijit/Downloads/video frames/optical flow/optical flow/crowdgroundtruth.xlsx'\n",
    "dataroot_2 = '/home/abhijit/Downloads/video frames/optical flow/'\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading The Ground Truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = pd.read_excel(csv, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(all_, test_size=0.3, random_state = 0)\n",
    "valid_df, test_df = train_test_split(test_df, test_size=.66, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader for Cycle GAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANDataset(Dataset):\n",
    "    \n",
    "\n",
    "    def __init__(self, csv_file,root_dir,df,root_dir_2, transform=None):\n",
    "\n",
    "        self.landmarks_frame = pd.read_excel(csv_file, header = 0)\n",
    "        self.read_number = pd.read_excel(csv_file,header = 1)\n",
    "        self.root_dir = root_dir\n",
    "        self.root_dir_2 = root_dir_2\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        #return len(os.listdir(self.root_dir_2))\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.df.iloc[idx]['Frame1']\n",
    "        number_left = self.df.iloc[idx,3]\n",
    "        number_right = self.df.iloc[idx,4]\n",
    "        #number_combined = self.df.iloc[idx,5]\n",
    "        number_combined = number_left + number_right\n",
    "        #number_all = self.landmarks_frame['left_to_right'][idx:idx]\n",
    "        #number_all = 0\n",
    "        number_all = np.array([number_left,number_right, number_combined])\n",
    "        \n",
    "        ix = ['scene1','scene2','scene3','scene4','scene5','scene6','scene7','scene8','scene9', 'scene10','scene11','scene12','scene13','scene14','scene15']\n",
    "        jx = ['scene10','scene11','scene12','scene13','scene14','scene15']\n",
    "\n",
    "#img_name = 'scene6medcam1frame780'\n",
    "        i = ''\n",
    "        x = 0\n",
    "        for j in jx:\n",
    "            if j in img_name:\n",
    "                x = 1\n",
    "                break\n",
    "        i = j\n",
    "        if x==0:\n",
    "            for i in ix:\n",
    "                if i in img_name:\n",
    "                    break\n",
    "        \n",
    "        dense = ['low', 'med', 'high']\n",
    "        cam = ['cam1', 'cam2', 'cam3']\n",
    "        occlu = ['', 'occlu']   \n",
    "\n",
    "        for den in dense:\n",
    "            if den in img_name:\n",
    "                break\n",
    "        for c in cam:\n",
    "            if c in img_name:\n",
    "                break\n",
    "            \n",
    "        if 'occlu' in img_name:\n",
    "            occ = 'occlu'\n",
    "        else:\n",
    "            occ= ''\n",
    "        \n",
    "        #image = io.imread(self.root_dir+'scene' + str(i)+'/'+'scene'+str(i)+den+c+occ+'/'+img_name )\n",
    "        img = self.root_dir+ str(i)+'/'+str(i)+den+c+occ+'/'+img_name+'.jpg'\n",
    "        \n",
    "        #optical_flow = self.root_dir_2 + str(i)+'/'+str(i)+den+c+occ+'/'+img_name+'.png'\n",
    "        image = io.imread(img)\n",
    "        image = Image.fromarray(image)\n",
    "        #op_flow = io.imread(optical_flow)\n",
    "        #op_flow = Image.fromarray(op_flow)\n",
    "        origi = image\n",
    "        image = self.transform(image)\n",
    "        #op_flow = self.transform(op_flow)\n",
    "        \n",
    "        \n",
    "        #dirs2 = os.listdir(self.root_dir_2)\n",
    "        \n",
    "        #image_2 = self.root_dir_2+ '/' +dirs2[idx]   \n",
    "        \n",
    "        image_2 = img\n",
    "        image_2 = Image.open(image_2)\n",
    "        #image_2 = convert_gray2rgb(image_2)\n",
    "        image_2 = image_2.convert(\"RGB\")\n",
    "        #image = convert_gray2rgb(image)\n",
    "        \n",
    "        \n",
    "        image_2 = self.transform(image_2)\n",
    "        \n",
    "        every_thing = {'image': image,\n",
    "                        'img_root':img,\n",
    "                       'image_2': image_2,\n",
    "                       'img_2_name': img_name,\n",
    "                      'left_to_right': number_left,\n",
    "                      'right_to_left': number_right,\n",
    "                      'combined':number_combined,\n",
    "                      'all':number_all\n",
    "                }\n",
    "        \n",
    "\n",
    "        return every_thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "train_dataset = GANDataset(csv, dataroot, all_,dataroot,\n",
    "                                    transform = transforms.Compose([ transforms.Resize([256,256]),  transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified Cycle GAN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [  nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.ReflectionPad2d(1),\n",
    "                        nn.Conv2d(in_features, in_features, 3),\n",
    "                        nn.InstanceNorm2d(in_features)  ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block       \n",
    "        model = [   nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(input_nc, 64, 7),\n",
    "                    nn.InstanceNorm2d(64),\n",
    "                    nn.ReLU(inplace=True) ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
    "                        nn.InstanceNorm2d(out_features),\n",
    "                        nn.ReLU(inplace=True) ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        # Output layer\n",
    "        model += [  nn.ReflectionPad2d(3),\n",
    "                    nn.Conv2d(64, output_nc, 7),\n",
    "                    nn.Tanh() ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # A bunch of convolutions one after another\n",
    "        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
    "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        #model += [  nn.Conv2d(32, 32, 4, stride=2, padding=1),\n",
    "        #            nn.InstanceNorm2d(128), \n",
    "         #           nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        #model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "         #           nn.InstanceNorm2d(256), \n",
    "          #          nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        #model += [  nn.Conv2d(64, 128, 4, padding=1),\n",
    "            #        nn.InstanceNorm2d(512), \n",
    "          #          nn.LeakyReLU(0.2, inplace=True) ]\n",
    "\n",
    "        # FCN classification layer\n",
    "        model += [nn.Conv2d(64, 1, 4, padding=1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x =  self.model(x)\n",
    "        # Average pooling and flatten\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B = Generator(3, 3)\n",
    "netG_B2A = Generator(3, 3)\n",
    "netD_A = Discriminator(3)\n",
    "netD_B = Discriminator(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B.cuda()\n",
    "#torch.cuda.empty_cache()\n",
    "netG_B2A.cuda()\n",
    "#torch.cuda.empty_cache()\n",
    "netD_A.cuda()\n",
    "#torch.cuda.empty_cache()\n",
    "netD_B.cuda()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator and Discriminator Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A.apply(weights_init_normal)\n",
    "netD_A.apply(weights_init_normal)\n",
    "netD_B.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from math import exp\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average = True):\n",
    "    mu1 = F.conv2d(img1, window, padding = window_size//2, groups = channel)\n",
    "    mu2 = F.conv2d(img2, window, padding = window_size//2, groups = channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding = window_size//2, groups = channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding = window_size//2, groups = channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding = window_size//2, groups = channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size = 11, size_average = True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "def ssim(img1, img2, window_size = 11, size_average = True):\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses for Cycle GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer for Cycle GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "                                lr= .0002, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr= .0002, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr= .0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Schedular for Cycle GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "class LambdaLR():\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
    "\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(50, 0, 25).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda = LambdaLR(50, 0 ,25).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(50, 0, 25).step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Buffer to Hold the Previous outputs from Generator During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import random\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0,1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size-1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of Cycle GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for i, data in enumerate(train_loader):        \n",
    "        \n",
    "        real_A = Variable(data['image'].cuda())\n",
    "        real_B = Variable(data['image_2'].cuda())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        target_real = Variable(torch.tensor(len(data['image'])).fill_(1.0).float(), requires_grad=False).cuda()\n",
    "        target_fake = Variable(torch.tensor(len(data['image'])).fill_(0.0).float(), requires_grad=False).cuda()\n",
    "        \n",
    "        \n",
    "        #real_A = Variable(data['image'])\n",
    "        #real_B = Variable(data['image_2'])        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #target_real = Variable(torch.tensor(len(data['image'])).fill_(1.0).float(), requires_grad=False)\n",
    "        #target_fake = Variable(torch.tensor(len(data['image'])).fill_(0.0).float(), requires_grad=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###### Generators A2B and B2A ######\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        same_B = netG_A2B(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)* 5.0\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = netG_B2A(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)* 5.0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        pred_fake = netD_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        pred_fake = netD_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_A = netG_B2A(fake_B)\n",
    "        loss_cycle_ABA = (criterion_cycle(recovered_A, real_A)* 10.0)\n",
    "\n",
    "         \n",
    "        \n",
    "        #seamese loss for 1st image\n",
    "        #siamese_1.load_state_dict(torch.load('/home/abhijit/Documents/saved_models/Siamese_game.pth'))\n",
    "        with torch.no_grad():       \n",
    "         #   x1, x2 = siamese_1(real_A,fake_B)\n",
    "            SSIM_B2A = 1 -ssim_loss(real_A,recovered_A).detach()\n",
    "        \n",
    "        \n",
    "        #label = 0\n",
    " \n",
    "        \n",
    "            \n",
    "        #if SSIM_B2A > .1:\n",
    "         #   label = 0\n",
    "        #else:\n",
    "         #   label = 1 \n",
    "        \n",
    "        #same_loss_1 = 2* loss(x1, x2,1 )\n",
    "\n",
    "        #p = same_loss_1\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #simease end for 1st image\n",
    "\n",
    "        recovered_B = netG_A2B(fake_A)\n",
    "        loss_cycle_BAB = (criterion_cycle(recovered_B, real_B)* 10.0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #siamese_2.load_state_dict(torch.load('/home/abhijit/Documents/saved_models/Siamese_real.pth')) \n",
    "        \n",
    "        #2nd siamese loss\n",
    "        with torch.no_grad():\n",
    "         #   x1, x2 = siamese_2(real_B,fake_A)\n",
    "            SSIM_A2B = 1 -ssim_loss(real_B, recovered_B).detach()\n",
    " \n",
    "        #if SSIM_A2B > .1:\n",
    "         #   label = 0\n",
    "        #else:\n",
    "         #   label = 1 \n",
    "        \n",
    "        #same_loss_2 = 2* loss_2(x1, x2,1 )\n",
    "    \n",
    "    \n",
    "        \n",
    "       # q = same_loss_2\n",
    "        \n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        #SSIM Loss\n",
    "        \n",
    "        #fake_B = netG_A2B(real_A)\n",
    "        #pred_fake = netD_B(fake_B)\n",
    "        #SSIM_B2A = -ssim_loss(fake_B, real_A)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        #fake_A = netG_B2A(real_B)\n",
    "        #pred_fake = netD_A(fake_A)\n",
    "        #SSIM_A2B = -ssim_loss(fake_A, real_B)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Total loss\n",
    "        loss_G = (loss_identity_A + loss_identity_B + loss_GAN_A2B +\n",
    "                  loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB + SSIM_B2A + SSIM_A2B)\n",
    "        \n",
    "        \n",
    "        #loss_G = (  loss_GAN_A2B +\n",
    "         #        loss_identity_A + loss_identity_B+ \n",
    "          #         loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB)\n",
    "        #same_loss_1 + same_loss_2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss_G = loss_G.float()\n",
    "        \n",
    "        \n",
    "        #print(loss_G)\n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        \n",
    "        \n",
    "    #           with torch.no_grad(): \n",
    "    \n",
    "        #1st siamese network\n",
    "        \n",
    "        #optimizer_1.zero_grad()\n",
    "        #x1, x2 = siamese_1(recovered_A.detach(), real_A)\n",
    "        #SSIM_B2A = 1 -ssim_loss(recovered_A, real_A).detach()\n",
    "        \n",
    "        \n",
    "        #label = 0\n",
    " \n",
    "        \n",
    "            \n",
    "        #if SSIM_B2A > .1:\n",
    "         #   label = 0\n",
    "        #else:\n",
    "         #   label = 1 \n",
    "        \n",
    "        #same_loss_1 = 1* loss_1(x1, x2,label )\n",
    "        \n",
    "        \n",
    "        \n",
    "        #same_loss =  loss(x1, x2,label )\n",
    "        #same_loss_1.backward()\n",
    "        #optimizer_1.step()\n",
    "        \n",
    "        \n",
    "    #            with torch.no_grad():\n",
    "    \n",
    "        #2nd siamese network\n",
    "        \n",
    "        #optimizer_2.zero_grad()\n",
    "        #x1, x2 = siamese_2(recovered_B.detach(), real_B)\n",
    "        #SSIM_A2B = 1 -ssim_loss(recovered_B, real_B).detach()\n",
    " \n",
    "        #if SSIM_A2B > .1:\n",
    "          #  label = 0\n",
    "       # else:\n",
    "            #label = 1 \n",
    "        \n",
    "       # same_loss_2 = 1* loss_2(x1, x2,label )\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        #same_loss =  loss(x1, x2,label )\n",
    "        #same_loss_2.backward()\n",
    "       # optimizer_2.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = netD_A(real_A)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "        # Fake loss\n",
    "        fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "        pred_fake = netD_A(fake_A.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_A = ((loss_D_real + loss_D_fake)*0.5)\n",
    "        loss_D_A.backward()\n",
    "\n",
    "        optimizer_D_A.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator B ######\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        pred_real = netD_B(real_B)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "        pred_fake = netD_B(fake_B.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #siamese update\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "                \n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                \n",
    "        if ( epoch % 1)==0 and  (i%400)== 0:\n",
    "            print(\"epoch: %d loss_D_A: %f   loss_D_B: %f loss_G: %f ,SSIM_1 :%f  SSIM_2: %f \\n\"\n",
    "                  %(epoch, loss_D_A, loss_D_B, loss_G, SSIM_B2A,SSIM_A2B) )\n",
    "            print(epoch)\n",
    "            from matplotlib.pyplot import figure\n",
    "            figure(num=1, figsize=(6, 6))\n",
    "            print('from game image \\n')\n",
    "            image = fake_B[0].cpu()\n",
    "            image = (image* .5 + .5)\n",
    "                    #plt.imshow(image)\n",
    "            plt.imshow(image.permute(1, 2, 0)  )\n",
    "            plt.show()\n",
    "            \n",
    "            print('from real image')\n",
    "            figure(num=1, figsize=(6, 6))\n",
    "            image_2 = fake_A[0].cpu()\n",
    "                    #plt.imshow(image)\n",
    "            image_2 = (image_2 *.5 + 0.5  )\n",
    "            plt.imshow(image_2.permute(1, 2, 0)  )        \n",
    "            \n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    " \n",
    "    #scheduler_1.step()\n",
    "    #scheduler_2.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating Synthetic Image to Real Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for i, data in enumerate(train_loader):        \n",
    "        \n",
    "        real_A = Variable(data['image'].cuda())\n",
    "        real_B = Variable(data['image_2'].cuda())\n",
    "        \n",
    "        \n",
    "        x1, x2 = siamese_1(real_A,netG_A2B(real_A))\n",
    "        test_1 = loss(x1, x2, 1)\n",
    "        \n",
    "        ssim =  1 - ssim_loss(real_A, (netG_A2B(real_A)))\n",
    "        print(\"test_1 : %f, ssim : %f\"%(test_1, ssim))\n",
    "        \n",
    "        fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
    "        fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
    "\n",
    "    # Save image files\n",
    "        from matplotlib.pyplot import figure\n",
    "        figure(num=3,figsize = (8,8))\n",
    "        #plt.imshow(((data['image'][0].cpu()).permute(1, 2, 0)+1)*.5)\n",
    "        #plt.imsave( '/home/abhijit/Documents/game_output/'+str(i)+ 'a.png', ((data['image'][0].cpu()).permute(1, 2, 0)+1)*.5 )    \n",
    "\n",
    "        from matplotlib.pyplot import figure\n",
    "        figure(num=1, figsize=(8, 8))\n",
    "        #plt.imshow((fake_B[0].cpu()).permute(1, 2, 0))\n",
    "        plt.imsave( '/home/abhijit/Documents/finalgamee/cycleandssim/'+data['img_2_name'][0]+ '.png' ,(fake_B[0].cpu()).permute(1, 2, 0))\n",
    "        \n",
    "        \n",
    "        figure(num=2, figsize=(8, 8))\n",
    "        #plt.imshow((fake_A[0].cpu()).permute(1, 2, 0))\n",
    "        #plt.imsave( '/home/abhijit/Documents/boleizhou_output/siamese_identity/'+data['img_2_name'][0]+'.png' ,(fake_A[0].cpu()).permute(1, 2, 0))\n",
    " \n",
    "\n",
    "        figure(num=4, figsize = (8,8))\n",
    "        #plt.imshow(((data['image_2'][0].cpu()).permute(1, 2, 0)+1)*.5)\n",
    "        #plt.imsave( '/home/abhijit/Documents/output2/from real/'+str(i) +'a.png', ((data['image_2'][0].cpu()).permute(1, 2, 0)+1)*.5)\n",
    "\n",
    "                \n",
    "        if ( epoch % 5)==0 and  (i%400)== 0:\n",
    "            from matplotlib.pyplot import figure\n",
    "            figure(num=1, figsize=(10, 10))\n",
    "            print('from game image \\n')\n",
    "            image = netG_B2A(fake_B).detach()\n",
    "            image = image[0].cpu()\n",
    "            image = (image* .5+.5)\n",
    "                    #plt.imshow(image)\n",
    "            plt.imshow(image.permute(1, 2, 0)  )\n",
    "            plt.show()\n",
    "            \n",
    "            #print('from real image')\n",
    "            #figure(num=1, figsize=(10, 10))\n",
    "            #image_2 = fake_A[0].cpu()\n",
    "                    #plt.imshow(image)\n",
    "            #image_2 = (image_2 *.5 +.5  )\n",
    "            #plt.imshow(image_2.permute(1, 2, 0)  )        \n",
    "            \n",
    "            \n",
    "            #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
