{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os, sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '/home/abhijit/Downloads/video frames/crowd/'\n",
    "csv = '/home/abhijit/Downloads/video frames/optical flow/optical flow/crowdgroundtruth.xlsx'\n",
    "dataroot_2 = '/home/abhijit/Downloads/video frames/optical flow/'\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Groung Truth for Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ = pd.read_excel(csv, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(all_, test_size=0.3, random_state = 0)\n",
    "valid_df, test_df = train_test_split(test_df, test_size=.66, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index()\n",
    "valid_df = valid_df.reset_index()\n",
    "test_df = test_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDataset(Dataset):\n",
    "    \n",
    "\n",
    "    def __init__(self, csv_file,root_dir,df,root_dir_2, transform=None):\n",
    "       \n",
    "        self.landmarks_frame = pd.read_excel(csv_file, header = 0)\n",
    "        self.read_number = pd.read_excel(csv_file,header = 1)\n",
    "        self.root_dir = root_dir\n",
    "        self.root_dir_2 = root_dir_2\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.df.iloc[idx]['Frame1']\n",
    "        number_left = self.df.iloc[idx,3]\n",
    "        number_right = self.df.iloc[idx,4]\n",
    "        number_combined = self.df.iloc[idx,5]\n",
    "        #number_all = self.landmarks_frame['left_to_right'][idx:idx]\n",
    "        #number_all = 0\n",
    "        number_all = np.array([number_left,number_right, number_combined])\n",
    "        \n",
    "        ix = ['scene1','scene2','scene3','scene4','scene5','scene6','scene7','scene8','scene9', 'scene10','scene11','scene12','scene13','scene14','scene15']\n",
    "        jx = ['scene10','scene11','scene12','scene13','scene14','scene15']\n",
    "\n",
    "#img_name = 'scene6medcam1frame780'\n",
    "        i = ''\n",
    "        x = 0\n",
    "        for j in jx:\n",
    "            if j in img_name:\n",
    "                x = 1\n",
    "                break\n",
    "        i = j\n",
    "        if x==0:\n",
    "            for i in ix:\n",
    "                if i in img_name:\n",
    "                    break\n",
    "        \n",
    "        dense = ['low', 'med', 'high']\n",
    "        cam = ['cam1', 'cam2', 'cam3']\n",
    "        occlu = ['', 'occlu']   \n",
    "\n",
    "        for den in dense:\n",
    "            if den in img_name:\n",
    "                break\n",
    "        for c in cam:\n",
    "            if c in img_name:\n",
    "                break\n",
    "            \n",
    "        if 'occlu' in img_name:\n",
    "            occ = 'occlu'\n",
    "        else:\n",
    "            occ= ''\n",
    "        \n",
    "        #image = io.imread(self.root_dir+'scene' + str(i)+'/'+'scene'+str(i)+den+c+occ+'/'+img_name )\n",
    "        #img = self.root_dir+ str(i)+'/'+str(i)+den+c+occ+'/'+img_name+'.jpg'\n",
    "        img = self.root_dir+ '/'+img_name+'.png'\n",
    "        optical_flow = self.root_dir_2 + str(i)+'/'+str(i)+den+c+occ+'/'+img_name+'.png'\n",
    "        #image = io.imread(img)\n",
    "        #image = Image.fromarray(image)\n",
    "        \n",
    "        image = Image.open(img).convert('RGB')\n",
    "        op_flow = io.imread(optical_flow)\n",
    "        op_flow = Image.fromarray(op_flow)\n",
    "        origi = image\n",
    "        image = self.transform(image)\n",
    "        op_flow = self.transform(op_flow)\n",
    "        \n",
    "        every_thing = {'image': image,\n",
    "                        'img_root':img,\n",
    "                       'optical_flow':op_flow,\n",
    "                      'left_to_right': number_left,\n",
    "                      'right_to_left': number_right,\n",
    "                      'combined':number_combined,\n",
    "                      'all':number_all\n",
    "                }\n",
    "        \n",
    "\n",
    "        return every_thing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dataset Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot3 = '/home/abhijit/Documents/RealData/removeback/1stvideo'\n",
    "dataroot4 = '/home/abhijit/Documents/RealData/removebackoptical/1stvideo'\n",
    "\n",
    "df4 = '/home/abhijit/Documents/RealData/ground.xlsx'\n",
    "df4 = pd.read_excel(df4, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel(df2, header = 0)\n",
    "df3 = pd.read_excel(df3, header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df2,df3,df4],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset_test =  SyntheticDataset2( dataroot1,dataroot2,test_df_2,\n",
    "                                    transform = transforms.Compose([ transforms.Resize([227,227]),  transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "real_loader_test = torch.utils.data.DataLoader(real_dataset_test, batch_size= 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet as CNN Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import torch.utils.model_zoo\n",
    "\n",
    "\n",
    "class AlexNet_modified(nn.Module):\n",
    "    def __init__(self, alexnet, n_class=1000):\n",
    "        super(AlexNet_modified, self).__init__()\n",
    "        # conv1\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        # self.bn1 = nn.BatchNorm2d(64, momentum=0.1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        # LRN(local_size=5, alpha=0.0001, beta=0.75)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        # conv2\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        # self.bn2 = nn.BatchNorm2d(192, momentum=0.1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        # LRN(local_size=5, alpha=0.0001, beta=0.75)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        # conv3\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        # self.bn3 = nn.BatchNorm2d(384, momentum=0.1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # conv4\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        # self.bn4 = nn.BatchNorm2d(256, momentum=0.1)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # conv5\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        # self.bn5 = nn.BatchNorm2d(256, momentum=0.1)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        # self.pool5 = nn.AdaptiveAvgPool2d(6)\n",
    "        self.drop5 = nn.Dropout()\n",
    "\n",
    "        # fc6\n",
    "        self.fc6 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.drop6 = nn.Dropout()\n",
    "\n",
    "        # fc7\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # fc8 this is the extra layer\n",
    "        self.fc8 = nn.Linear(4096*2,4096)\n",
    "        self.fc9 = nn.Linear(4096,1024)\n",
    "        self.fc10 = nn.Linear(1024, 512)\n",
    "        self.fc11 = nn.Linear(512, n_class)\n",
    "        self.copy_params_from_alexnet(alexnet)\n",
    "\n",
    "    def sequence(self, x):\n",
    "        h = x\n",
    "        # h = self.relu1(self.bn1(self.conv1(h)))\n",
    "        h = self.relu1(self.conv1(h))\n",
    "        h = self.pool1(h)\n",
    "\n",
    "        # h = self.relu2(self.bn2(self.conv2(h)))\n",
    "        h = self.relu2(self.conv2(h))\n",
    "        h = self.pool2(h)\n",
    "\n",
    "        # h = self.relu3(self.bn3(self.conv3(h)))\n",
    "        h = self.relu3(self.conv3(h))\n",
    "\n",
    "        # h = self.relu4(self.bn4(self.conv4(h)))\n",
    "        h = self.relu4(self.conv4(h))\n",
    "\n",
    "        # h = self.relu5(self.bn5(self.conv5(h)))\n",
    "        h = self.relu5(self.conv5(h))\n",
    "        h = self.pool5(h)\n",
    "        h = self.drop5(h)\n",
    "\n",
    "        h = h.view(-1, 256 * 6 * 6)\n",
    "        h = self.relu6(self.fc6(h))\n",
    "        h = self.drop6(h)\n",
    "\n",
    "        h = self.relu7(self.fc7(h))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        return h\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # branch 1\n",
    "        h1 = self.sequence(x1)\n",
    "\n",
    "        # branch 2\n",
    "        h2 = self.sequence(x2)\n",
    "\n",
    "        # merge two branches\n",
    "\n",
    "        group = torch.cat((h1, h2), 1)\n",
    "        \n",
    "        h = self.relu7(self.fc8(group))\n",
    "        h = self.relu7(self.fc9(h))    \n",
    "        h = self.relu7(self.fc10(h))\n",
    "        o = self.fc11(h)\n",
    "        return o\n",
    "\n",
    "    def copy_params_from_alexnet(self, alexnet):\n",
    "        features = [\n",
    "            self.conv1, self.relu1,\n",
    "            self.pool1,\n",
    "            self.conv2, self.relu2,\n",
    "            self.pool2,\n",
    "            self.conv3, self.relu3,\n",
    "            self.conv4, self.relu4,\n",
    "            self.conv5, self.relu5,\n",
    "            self.pool5,\n",
    "        ]\n",
    "        for l1, l2 in zip(alexnet.features, features):\n",
    "            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
    "                assert l1.weight.size() == l2.weight.size()\n",
    "                assert l1.bias.size() == l2.bias.size()\n",
    "                l2.weight.data = l1.weight.data\n",
    "                l2.bias.data = l1.bias.data\n",
    "        for i, name in zip([1, 4], ['fc6', 'fc7']):\n",
    "            l1 = alexnet.classifier[i]\n",
    "            l2 = getattr(self, name)\n",
    "            l2.weight.data = l1.weight.data.view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data.view(l2.bias.size())\n",
    "\n",
    "\n",
    "def main(paras):\n",
    "    if paras == 'alexnet':\n",
    "        model = models.alexnet(pretrained=True)\n",
    "        net_modified = AlexNet_modified(model, 3)\n",
    "\n",
    "    return net_modified\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main('alexnet')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "epoch = 50\n",
    "\n",
    "lr = 1e-5\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizerD = optim.Adam(b.parameters(), lr= 1e-4)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizerD, step_size=10, gamma=0.1)\n",
    "\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "\n",
    "train_min = 5000\n",
    "valid_min = 5000\n",
    "train_error_all = list()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_error = 0\n",
    "    valid_error= 0\n",
    "    b.train()\n",
    "    for i, data in enumerate(real_loader,0):\n",
    "        \n",
    "    \n",
    "\n",
    "        image = data['image']\n",
    "        optical_flow = data['optical_flow']\n",
    "        \n",
    "        \n",
    "        image = Variable(image.cuda())\n",
    "        optical_flow = Variable(optical_flow.cuda())\n",
    "        target = Variable(data['all'].float()).cuda()\n",
    "        \n",
    "        \n",
    "        \n",
    "     \n",
    "    \n",
    "        \n",
    "        c = b(image, optical_flow)\n",
    "        \n",
    "\n",
    "        error = loss(c, target)\n",
    "        #error = torch.tensor(error, requires_grad=True)\n",
    "        #error = torch.tensor(.5)\n",
    "        #error = torch.tensor(error, dtype = 'float')\n",
    "        #error = error.float()\n",
    "        train_error +=error\n",
    "        #if (i % 15) == 0:\n",
    "            #print(c)\n",
    "            #print(data['all'])\n",
    "        \n",
    "            #print('\\n \\n')    \n",
    "            \n",
    "            #print(error)\n",
    "        optimizerD.zero_grad()\n",
    "        error.backward()\n",
    "        optimizerD.step()\n",
    "        #print(5)\n",
    "        #print(d)\n",
    "        #print('\\n \\n')\n",
    "        #print(target)\n",
    "        \n",
    "    train_error = train_error/(i+1)\n",
    "    if train_error < train_min:\n",
    "        train_min =  train_error\n",
    "        \n",
    "    train_error_all.append(train_error)\n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        b.eval()\n",
    "        for i, data_sample in enumerate(real_loader_test):\n",
    "            image = data_sample['image']\n",
    "            optical_flow = data_sample['optical_flow']\n",
    "        \n",
    "        \n",
    "            image = Variable(image.cuda())\n",
    "            optical_flow = Variable(optical_flow.cuda())\n",
    "            target = Variable(data_sample['all'].float()).cuda()\n",
    "        \n",
    "        \n",
    "        \n",
    "     \n",
    "    \n",
    "        \n",
    "            c = model(image, optical_flow)\n",
    "            \n",
    "            #if epoch % 20 ==0:\n",
    "                \n",
    "             #   print(data_sample['all'])\n",
    "              #  print('\\n')\n",
    "               # print(c)\n",
    "                #print(\"\\n \\n\")\n",
    "        \n",
    "\n",
    "            error = loss(c, target)\n",
    "        \n",
    "            valid_error += error\n",
    "        \n",
    "        valid_error = valid_error/(i+1)\n",
    "\n",
    "    \n",
    "        if valid_error < valid_min:\n",
    "            valid_min =  valid_error\n",
    "    \n",
    "        \n",
    "            torch.save({ 'epoch':epoch, 'model':b, 'state_dict': model.state_dict(),\n",
    "                                   'optimizer_state_dict': optimizerD.state_dict(),\n",
    "                'loss': train_error}, '/home/abhijit/Documents/saved_models/b_final_finetune_onreal')\n",
    "        \n",
    "    print('train_error: %f   valid_error: %f' %(train_error, valid_error))\n",
    "    \n",
    "    exp_lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "\n",
    "\n",
    "test_error_all = list()\n",
    "ground_truth_all = list()\n",
    "\n",
    "test_error_all_ucsd = list()\n",
    "ground_all_ucsd = list()\n",
    "test_error_all_bolei = list()\n",
    "ground_truth_all_bolei = list()\n",
    "test_error = 0\n",
    "test_error_all_my = list()\n",
    "\n",
    "ground_truth_my = list()\n",
    "ucsd = 0\n",
    "bolei = 0\n",
    "my_ = 0\n",
    "if a ==1: \n",
    "    with torch.set_grad_enabled(False):\n",
    "\n",
    "        b.eval()\n",
    "        for i, data_sample in enumerate(real_loader_test):\n",
    "            image = data_sample['image']\n",
    "            optical_flow = data_sample['optical_flow']\n",
    "        \n",
    "        \n",
    "            image = Variable(image.cuda())\n",
    "            optical_flow = Variable(optical_flow.cuda())\n",
    "            target = Variable(data_sample['all'].float()).cuda()\n",
    "        \n",
    "        \n",
    "        \n",
    "     \n",
    "    \n",
    "        \n",
    "            c = b(image, optical_flow)\n",
    "            \n",
    "            \n",
    "            test_error_all.append(c)\n",
    "            ground_truth_all.append(target)\n",
    "            \n",
    "            #print(data_sample['type'])\n",
    "            \n",
    "            if data_sample['type'][0] == 'bolei':\n",
    "                test_error_all_bolei.append(c)\n",
    "              #\n",
    "                ground_truth_all_bolei.append(target)\n",
    "                bolei +=1\n",
    "                #print(bolei)\n",
    "                \n",
    "            elif data_sample['type'][0]=='mydata':\n",
    "                \n",
    "                test_error_all_my.append(c)\n",
    "\n",
    "                ground_truth_my.append(target)\n",
    "                my_ +=1\n",
    "                \n",
    "            else:   \n",
    "                \n",
    "                test_error_all_ucsd.append(c)\n",
    "                ground_all_ucsd.append(target)\n",
    "                ucsd +=1\n",
    "            \n",
    "            #a = 1\n",
    "            if (i%25)  :\n",
    "                \n",
    "                trans = transforms.ToPILImage()\n",
    "                img = data_sample['img_root']\n",
    "                image = io.imread(img[0])\n",
    "        #plt.imshow(image)\n",
    "        #print(data['image'].shape)\n",
    "        #image = data['optical_flow'][0]\n",
    "        #plt.imshow(image)\n",
    "                #plt.imshow(image.permute(1, 2, 0)  )\n",
    "                #images = image.cpu()\n",
    "                #images = io.imread(images[0])\n",
    "                #images = images[0].permute(1,2,0)\n",
    "                #images = images[0]\n",
    "                #unnorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "                #images = unnorm(images)\n",
    "                #images = images/2 + .416\n",
    "                #images[0] = images[0]*.229 +.486\n",
    "                #images[1]= images[1]*.224+.456\n",
    "               # images[2] = images[2]*.225 +.406\n",
    "                #im = Image.open(images)\n",
    "                #im = transforms.ToPILImage()(images[0]).convert(\"RGB\")\n",
    "                #display(im)\n",
    "                #plt.imshow(trans(images[0])).convert('RGB')\n",
    "                #plt.show()\n",
    "                #plt.figure(10,10)\n",
    "                from matplotlib.pyplot import figure\n",
    "                #figure(10,10)\n",
    "                plt.figure(figsize=(6,6))\n",
    "                plt.imshow(image, cmap = 'gray')\n",
    "                plt.show()\n",
    "                print('Ground Truth \\n')\n",
    "                print(data_sample['all'][0])\n",
    "                print('\\n')\n",
    "                print('Predicted \\n')\n",
    "                print(c[0])\n",
    "                print(\"\\n \\n\")\n",
    "            \n",
    "\n",
    "            #error = loss(c, target)\n",
    "            #test_error_all.append(c)\n",
    "            #ground_all.append(target)\n",
    "        \n",
    "            #test_error += error\n",
    "        \n",
    "        #test_error = test_error/(i+1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
